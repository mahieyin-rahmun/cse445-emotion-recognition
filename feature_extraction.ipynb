{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HUU8Xfipos1"
      },
      "source": [
        "import numpy as np\n",
        "import os \n",
        "import cv2 as cv\n",
        "import dlib\n",
        "from imutils.face_utils import shape_to_np\n",
        "import csv\n",
        "from math import atan, sqrt, floor\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knjvtz20uwBq"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKAj2SwQqC5R"
      },
      "source": [
        "class FeatureVector(object):\n",
        "  def __init__(self, facialLandmarksDatFilePath, emotionLabels = [\"angry\", \"disgust\", \"happy\", \"neutral\", \"sad\", \"surprise\"]):\n",
        "    self.detector = dlib.get_frontal_face_detector()\n",
        "    self.predictor = dlib.shape_predictor(facialLandmarksDatFilePath)\n",
        "    self.labelEncoder = LabelEncoder()\n",
        "    self.labelEncoder.fit(sorted(emotionLabels))\n",
        "\n",
        "\n",
        "  def __GetCenterOfGravityPoint(self, faceShape):\n",
        "    # initialize to zero\n",
        "    X_cog, Y_cog = (0, 0)\n",
        "\n",
        "    # sum up the x and y coords of the points\n",
        "    for i in range (len(faceShape)):\n",
        "      X_cog += faceShape[i][0]\n",
        "      Y_cog += faceShape[i][1]\n",
        "\n",
        "    # divide by the total number of points\n",
        "    X_cog = X_cog // len(faceShape)\n",
        "    Y_cog = Y_cog // len(faceShape)\n",
        "\n",
        "    return (X_cog, Y_cog)\n",
        "\n",
        "  \n",
        "  def __ComputeFeatureVector(self, faceShape, centerOfGravity):\n",
        "    cogX, cogY = centerOfGravity\n",
        "    # calculate the angle between the top point of nose and the tip of the nose for normalizing the image\n",
        "    angle_nose = (faceShape[28][1] - faceShape[31][1]) / (faceShape[28][0] - faceShape[31][0])\n",
        "    angle_nose = atan(angle_nose)\n",
        "\n",
        "    feature_vector = []\n",
        "\n",
        "    for i in range(len(faceShape)):\n",
        "      X_relative = faceShape[i][0] - cogX\n",
        "      Y_relative = faceShape[i][1] - cogY\n",
        "\n",
        "      # euclidean distance\n",
        "      euc = pow(X_relative, 2) + pow(Y_relative, 2)\n",
        "      euc = sqrt(euc)\n",
        "      \n",
        "      if X_relative > 0:\n",
        "        theta = atan(Y_relative / X_relative) - angle_nose\n",
        "      else:\n",
        "        theta = 0\n",
        "\n",
        "      feature_vector.append(X_relative)\n",
        "      feature_vector.append(Y_relative)\n",
        "      feature_vector.append(euc)\n",
        "      feature_vector.append(theta)\n",
        "      \n",
        "    return feature_vector\n",
        "\n",
        "\n",
        "  def ConstructFeatures(self, imagePath):\n",
        "    \"\"\"\n",
        "    Takes a single image, constructs the feature vector and returns it\n",
        "    \"\"\"\n",
        "    img = cv.imread(imagePath)\n",
        "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    rects = self.detector(gray, 1)\n",
        "    \n",
        "    if (len(rects) > 0):\n",
        "      rect = rects[0]\n",
        "      faceShape = self.predictor(gray, rect)\n",
        "      faceShape = shape_to_np(faceShape)\n",
        "\n",
        "      centerOfGravityPoint = self.__GetCenterOfGravityPoint(faceShape)\n",
        "      featureVector = self.__ComputeFeatureVector(faceShape, centerOfGravityPoint)\n",
        "\n",
        "      label = imagePath.rsplit(os.sep, 2)[-2]\n",
        "      featureVector.append(self.labelEncoder.transform([label])[0])\n",
        "\n",
        "      return np.asarray(featureVector)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LfBLtgUuQDK"
      },
      "source": [
        "ckPreprocessedRoot = \"/content/drive/My Drive/CSE445/CSE445 Dataset/ck-preprocessed\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHIW6E3mxJvq"
      },
      "source": [
        "fv = FeatureVector(\"/content/drive/My Drive/CSE445/shape_predictor_68_face_landmarks.dat\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx4WcWRguSU2"
      },
      "source": [
        "def DumpFeatureVectorsToCsv(processedDataRoot, fileSavePath):\n",
        "  featureVectors = []\n",
        "\n",
        "  for folderPath, subdirs, files in os.walk(processedDataRoot):\n",
        "    # skip first iteration\n",
        "    if len(files) == 0:\n",
        "      continue\n",
        "\n",
        "    for fileName in tqdm(files):\n",
        "      imagePath = os.path.join(folderPath, fileName)\n",
        "      featureVector = fv.ConstructFeatures(imagePath)\n",
        "      featureVectors.append(featureVector)\n",
        "    \n",
        "  featureVectors = np.asarray(featureVectors)\n",
        "  np.savetxt(fileSavePath, featureVectors, delimiter = \",\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHAGXzzovpFu",
        "outputId": "fe6002ad-8e42-4cbc-ccfa-c6c26ebcacb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "DumpFeatureVectorsToCsv(ckPreprocessedRoot, \"/content/drive/My Drive/CSE445/CSE445 Dataset/ck_features.csv\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 92/92 [01:51<00:00,  1.22s/it]\n",
            "100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n",
            "100%|██████████| 69/69 [01:24<00:00,  1.22s/it]\n",
            "100%|██████████| 96/96 [01:54<00:00,  1.19s/it]\n",
            "100%|██████████| 68/68 [01:22<00:00,  1.22s/it]\n",
            "100%|██████████| 68/68 [01:21<00:00,  1.19s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS8q6pUJvtpT",
        "outputId": "594bb1f0-d5e9-4acb-9a7f-9d644b715af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "jaffePreprocessedRoot = \"/content/drive/My Drive/CSE445/CSE445 Dataset/jaffe-preprocessed\"\n",
        "DumpFeatureVectorsToCsv(jaffePreprocessedRoot, \"/content/drive/My Drive/CSE445/CSE445 Dataset/jaffe_features.csv\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.33it/s]\n",
            "100%|██████████| 31/31 [00:09<00:00,  3.38it/s]\n",
            "100%|██████████| 31/31 [00:08<00:00,  3.54it/s]\n",
            "100%|██████████| 29/29 [00:08<00:00,  3.29it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.43it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK2U7xXwzFi5",
        "outputId": "0e5f30be-838b-49f0-da8b-4a4c45b01c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "kdefPreprocessedRoot = \"/content/drive/My Drive/CSE445/CSE445 Dataset/kdef-preprocessed\"\n",
        "DumpFeatureVectorsToCsv(kdefPreprocessedRoot, \"/content/drive/My Drive/CSE445/CSE445 Dataset/kdef_features.csv\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 140/140 [00:37<00:00,  3.71it/s]\n",
            "100%|██████████| 140/140 [00:36<00:00,  3.88it/s]\n",
            "100%|██████████| 140/140 [00:37<00:00,  3.76it/s]\n",
            "100%|██████████| 140/140 [00:37<00:00,  3.77it/s]\n",
            "100%|██████████| 139/139 [00:39<00:00,  3.56it/s]\n",
            "100%|██████████| 140/140 [00:36<00:00,  3.87it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEihBVyl3fTi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}